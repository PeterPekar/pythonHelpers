# JSON Chunks to Qdrant Uploader (`json_to_qdrant.py`)

This Python script loads text chunks and their associated metadata from a JSON file (typically generated by a document processing script like `docx_chunker.py`) and uploads them as vector embeddings to a Qdrant vector database.

## Features

*   Loads chunk data from a JSON file.
*   Uses `sentence-transformers` to generate text embeddings for each chunk.
*   Connects to a Qdrant instance (local, Docker, on-disk, or Qdrant Cloud).
*   Ensures the target Qdrant collection exists, creating it with appropriate vector parameters if necessary.
*   Verifies compatibility if the collection already exists.
*   Upserts chunks (embedding + payload) to Qdrant in batches.
*   Payload includes the original text content and all metadata from the input JSON.
*   Supports custom point IDs based on a metadata field, or generates UUIDs.
*   Configurable via command-line arguments for Qdrant connection, embedding model, collection parameters, and batching.

## Requirements

*   Python 3.8+
*   Required Python libraries:
    ```bash
    pip install qdrant-client sentence-transformers torch
    ```
    (`torch` is usually a dependency of `sentence-transformers` but can be installed explicitly if needed).

## Qdrant Setup (for Local Testing)

If you don't have a Qdrant instance running, the easiest way to get started for local testing is using Docker:

```bash
docker run -p 6333:6333 -p 6334:6334 \
    -v $(pwd)/qdrant_storage:/qdrant/storage \
    qdrant/qdrant
```

*   This command starts a Qdrant instance.
*   Port `6333` is exposed for HTTP access (used by default by the script).
*   Port `6334` is exposed for gRPC access.
*   The `-v $(pwd)/qdrant_storage:/qdrant/storage` part creates a local directory named `qdrant_storage` in your current working directory and mounts it into the Docker container for persistent storage. You can change `$(pwd)/qdrant_storage` to any absolute path on your host machine.

## Usage

Run the script from the command line:

```bash
python json_to_qdrant.py <input_json_file> <qdrant_collection_name> [options]
```

**Positional Arguments:**

*   `input_json_file`: Path to the input JSON file containing the list of chunks. Each chunk object should have at least `"content"` and `"metadata"` keys.
*   `qdrant_collection_name`: Name of the Qdrant collection to create or use.

**Optional Arguments:**

**Qdrant Connection:**
*   `--qdrant_url URL`: URL of the Qdrant instance (e.g., `http://localhost:6333`). Defaults to `http://localhost:6333` if this and `--qdrant_path` are not set. Can also be set via `QDRANT_URL` environment variable.
*   `--qdrant_path PATH`: Path to a local on-disk Qdrant database directory. If provided, this overrides `--qdrant_url`. Can also be set via `QDRANT_PATH` environment variable.
*   `--qdrant_api_key KEY`: API key for connecting to Qdrant Cloud. Can also be set via `QDRANT_API_KEY` environment variable.
*   `--prefer_grpc`: If specified, attempts to use gRPC for Qdrant connection (the server must be configured to accept gRPC, typically on a different port like 6334).
*   `--qdrant_timeout INT`: Timeout in seconds for Qdrant client operations (Default: `30`).

**Embedding and Collection Parameters:**
*   `--embedding_model TEXT`: Name of the `sentence-transformers` model to use for generating embeddings.
    *   Default: `'all-MiniLM-L6-v2'` (384 dimensions)
*   `--vector_name TEXT`: Name for the vector in Qdrant if using a named vector setup in your collection. If not provided, uses Qdrant's default (unnamed) vector.
    *   Default: `None`
*   `--distance_metric TEXT`: Distance metric for the Qdrant collection vectors (`Cosine`, `Euclidean`, `Dot`). This is used when creating the collection if it doesn't exist. If the collection exists, its metric must be compatible.
    *   Default: `'Cosine'`

**Batching and ID Parameters:**
*   `--batch_size INT`: Number of points to upsert to Qdrant in a single batch.
    *   Default: `64`
*   `--id_field TEXT`: Field name within each chunk's `metadata` to use as the Qdrant point ID. If not provided or the field is missing, a UUID will be generated for each point.
    *   Example: If your chunks have `{"metadata": {"my_unique_id": "chunk123", ...}}`, you can use `--id_field my_unique_id`.
    *   Default: `None` (generates UUIDs)

**Examples:**

1.  **Upload to a local Qdrant instance (new collection):**
    ```bash
    python json_to_qdrant.py my_chunks.json "tech_docs_collection"
    ```

2.  **Specify embedding model and use an existing local Qdrant path:**
    ```bash
    python json_to_qdrant.py my_chunks.json "docs_v2" --embedding_model "all-mpnet-base-v2" --qdrant_path "./my_qdrant_data"
    ```

3.  **Upload to Qdrant Cloud:**
    ```bash
    python json_to_qdrant.py my_chunks.json "cloud_collection_prod" --qdrant_url "https://your-cluster-url.qdrant.cloud:6333" --qdrant_api_key "YOUR_CLOUD_API_KEY"
    ```

4.  **Use a specific metadata field for point IDs and a larger batch size:**
    ```bash
    python json_to_qdrant.py my_chunks.json "docs_with_custom_ids" --id_field doc_chunk_id --batch_size 128
    ```

## Workflow

1.  **Load Chunks:** Reads the list of chunk objects from the input JSON file.
2.  **Initialize Embedding Model:** Loads the specified `sentence-transformers` model. The script dynamically determines the vector dimension required for Qdrant from this model.
3.  **Initialize Qdrant Client:** Connects to the Qdrant instance based on the provided URL, path, or cloud parameters.
4.  **Ensure Collection:**
    *   Checks if the specified Qdrant collection exists.
    *   If it exists, it verifies that its vector configuration (size, distance metric for the relevant vector name) is compatible with the loaded embedding model. If not, the script will raise an error.
    *   If it doesn't exist, the script creates it with the correct vector size and specified distance metric.
5.  **Process and Upsert:**
    *   Iterates through the loaded chunks in batches.
    *   For each chunk in a batch:
        *   Generates a vector embedding from its `"content"` field.
        *   Prepares a Qdrant point:
            *   **ID:** Uses the value of the `--id_field` from the chunk's metadata if specified and available; otherwise, generates a new UUID.
            *   **Vector:** The generated embedding.
            *   **Payload:** Contains two main keys:
                *   `"text_content"`: The original text content of the chunk.
                *   `"metadata"`: The complete metadata dictionary associated with the chunk from the input JSON.
    *   Upserts the batch of points to the Qdrant collection.
6.  **Completion:** Prints a summary upon successful completion or error messages if issues occur.

## Qdrant Payload Structure

Each point uploaded to Qdrant will have the following payload structure (example):

```json
{
  "text_content": "This is the actual text content of the processed chunk...",
  "metadata": {
    "source_filename": "my_document.docx",
    "heading_hierarchy": ["Chapter 1: Introduction", "Section 1.1: Overview"],
    "doc_chunk_id": 42,
    "estimated_char_count": 850
    // ... any other original metadata fields from the input JSON ...
  }
}
```
This structure allows you to retrieve the original text and all its associated metadata when you perform similarity searches in Qdrant.
